{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the TU Graz Repository!</p> <p>TU Graz Repository is a ready-to-go, turn-key Research Data Management repository and an instance of InvenioRDM.</p>"},{"location":"#development","title":"Development","text":"<p>Please visit the invenioRDM documentation for development section.</p> <p>&gt; Getting Started</p>"},{"location":"#deployment","title":"Deployment","text":"<p>Get to know current deployment workflow for Tu Graz repository .</p> <p>&gt; Deployment Guides</p>"},{"location":"#configs","title":"Configs","text":"<p>For more configurations such as How the gitlab-runners are registered? How the Database is setup? And so much more...</p> <p>&gt; Configurations</p>"},{"location":"#features","title":"Features","text":"<p>Get to know the specific features of TU Graz repository</p> <p>&gt; Features</p>"},{"location":"configs/","title":"Configurations","text":"<p>Configurations and setup of other services.</p> <p>&gt; Gitlab runner</p> <p>&gt; PostgreSQL</p> <p>&gt; SSH-key</p> <p>&gt; CEPH</p> <p>&gt; Override Pages</p>"},{"location":"configs/ceph/","title":"CephFS","text":"<p>The Ceph File System, or CephFS, is a POSIX-compliant file system built on top of Ceph\u2019s distributed object store, RADOS.</p>"},{"location":"configs/ceph/#cephfs-for-repository","title":"CephFS for repository","text":"<p>3 Folders were created for each environment:</p> <ol> <li> <p>Production environment - Quota 10TB</p> <p><code>/invenio/invenioprod: client 'fsinvenioprod', Secret in Sesam</code></p> </li> <li> <p>Test  environment - Quota 1TB</p> <p><code>/invenio/inveniotest: client 'fsinveniotest', Secret in Sesam</code></p> </li> <li> <p>Dev environment - Quota 1TB</p> <p><code>/invenio/inveniodev: client 'fsinveniodev', Secret in Sesam</code></p> </li> </ol> <p>In this guideline we will take a look on how the <code>CEPH FS</code> is configired for the production environment. Which is also the same for <code>Dev</code> and <code>Test</code> environments.</p>"},{"location":"configs/ceph/#steps","title":"Steps","text":""},{"location":"configs/ceph/#install-ceph-common","title":"install ceph-common","text":"<pre><code>apt install ceph-common\n</code></pre>"},{"location":"configs/ceph/#create-a-file","title":"Create a file","text":"<p>Create a file, and add the secret from sesam.tugraz</p> <pre><code>nano /etc/ceph/ceph.client.fsinvenioprod\n</code></pre>"},{"location":"configs/ceph/#create-a-mount-path","title":"Create a mount path","text":"<p>Create a directory which will be mounted to the CEPH FS.</p> <pre><code>mkdir /storage\n</code></pre>"},{"location":"configs/ceph/#test-mount","title":"Test mount","text":"<p>This will temporarily mount the directory <code>`/storage</code> to the <code>/invenio/invenioprod</code></p> <pre><code>mount -t ceph &lt;ip:port&gt;:/invenio/invenioprod /storage -o name=fsinvenioprod,secretfile=/etc/ceph/ceph.client.fsinvenioprod\n</code></pre>"},{"location":"configs/ceph/#check-mounted-file-systems","title":"Check mounted file systems:","text":"<pre><code>df -h\n</code></pre> <pre><code>Filesystem                                                                        Size  Used Avail Use% Mounted on\n&lt;ip:port&gt;:/invenio/invenioprod   size     0   size   0% /storage\n</code></pre>"},{"location":"configs/ceph/#unmount","title":"Unmount","text":"<p>After this temporarily mounting works, we will unmount it so later we can configure it properly.</p> <pre><code>umount /storage/\n</code></pre>"},{"location":"configs/ceph/#add-mount-configuration","title":"Add Mount configuration","text":"<p>open the <code>/etc/fstab</code> file and edit it as below:</p> <pre><code># &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;\n&lt;ip:port&gt;:/invenio/invenioprod /storage  ceph _netdev,name=fsinvenioprod,secretfile=/etc/ceph/ceph.client.fsinvenioprod 0 0\n</code></pre>"},{"location":"configs/ceph/#mount","title":"Mount","text":"<pre><code>mount /storage\n</code></pre>"},{"location":"configs/gitlab-runner/","title":"Gitlab Runner","text":"<p>GitLab Runner is an application that works with GitLab CI/CD to run jobs in a pipeline.</p> <p>Tu Graz Repository has a Gitlab group invenio. That has a group runner Gitlab-Runner-03-Produktion-Invenio-Shell, which is provided by ZID.</p> <p>We are using this group runner to run our Pipeline jobs, from gitlab to our VM server's.</p>"},{"location":"configs/gitlab-runner/#how-the-gitlab-runners-are-registered","title":"How the GitLab runners are registered?","text":"<ol> <li>Access the node - for example: <code>ssh mojib@instance_prod.tugraz.at</code> then enter your password from sesam.tugraz to gain access to the server.</li> <li> <p>Add GitLab\u2019s official repository.</p> <p><code>curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | sudo bash</code></p> </li> <li> <p>install the gitlab-runner</p> <p><code>apt install gitlab-runner</code></p> </li> <li> <p>Register the gitlab-runner for your group runner.</p> <p><code>gitlab-runner register</code></p> Input Value gitlab-ci URL: https://gitlab.tugraz.at/ gitlab-ci token: Check sesam.tugraz gitlab-ci description: invenio01-prod gitlab-ci tags: prod-one executor: shell </li> <li> <p>Make sure to give permission.</p> <p><code>usermod -aG docker gitlab-runner</code>.</p> </li> </ol> <p>Runner is registered successfully. Now you should be able to see your Gitlab-runner in the list here.</p>"},{"location":"configs/gitlab-runner/#possible-errors","title":"Possible Errors","text":"<p>These error might apear when using this registered runner for the first time.</p> <p>The runner throws an ERROR</p> <p>ERROR: Job failed (system failure): prepare environment: exit status 1 SEE HERE.</p> <p>Solution Remove/comment <code>.bash_logout</code> entries.</p> <ul> <li> <p>Access your VM server</p> </li> <li> <p>Navigate to <code>/home/gitlab-runner</code></p> </li> <li> <p>Look for file called <code>.bash_logout</code></p> </li> <li> <p>Remove or comment the entries on this file</p> </li> </ul> <p>Error saving credentials</p> <p><code>Error saving credentials: error storing credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY</code></p> <p>Solution: install package in VM</p> <p><code>apt install gnupg2 pass</code>.</p> <p>To learn more Gitlab-runner commands, visit the GitLab Runner commands.</p>"},{"location":"configs/override-pages/","title":"Override Pages","text":"<p>In some cases, the default pages do not offer all the functionality or modification possibilities needed. It is possible to override the pages, though this should be the last resort as it increases resources needed for maintainability.</p> <p>We will look into how to override some essential pages of <code>invenio-app-rdm</code> with our existing module <code>invenio-theme-tugraz</code>.</p> <p>! IMPORTANT: This is valid for <code>invenio-app-rdm==v6.0.2</code> !</p>"},{"location":"configs/override-pages/#main-search","title":"Main Search","text":"<p>The component to be overridden is <code>search</code> so the path for this looks like <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/search/</code>. Place the components in <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/search/components.js</code>.</p> <p>The original file can be found here: components.js</p>"},{"location":"configs/override-pages/#creating-search-app","title":"Creating Search App","text":"<p>Now that all components have been created or imported, create the following file <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/search/index.js</code>. In here, all the previously defined components will be imported and the search app will be defined.</p> <pre><code>import { createSearchAppInit } from \"@js/invenio_search_ui\";\nimport {\n  RDMBucketAggregationElement,\n  RDMRecordFacets,\n  RDMRecordFacetsValues,\n  RDMRecordResultsGridItem,\n  RDMRecordResultsListItem,\n  RDMRecordSearchBarContainer,\n  RDMRecordSearchBarElement,\n  RDMToggleComponent,\n  RDMCountComponent,\n} from \"./components\";\n\nconst initSearchApp = createSearchAppInit({\n  \"BucketAggregation.element\": RDMBucketAggregationElement,\n  \"BucketAggregationValues.element\": RDMRecordFacetsValues,\n  \"ResultsGrid.item\": RDMRecordResultsGridItem,\n  \"ResultsList.item\": RDMRecordResultsListItem,\n  \"SearchApp.facets\": RDMRecordFacets,\n  \"SearchApp.searchbarContainer\": RDMRecordSearchBarContainer,\n  \"SearchBar.element\": RDMRecordSearchBarElement,\n  \"SearchFilters.ToggleComponent\": RDMToggleComponent,\n  \"Count.element\": RDMCountComponent,\n});\n</code></pre>"},{"location":"configs/override-pages/#update-webpack","title":"Update webpack","text":"<p>Now that the functionality is done, it is important to add it to webpack. This makes it accessible to templates. Adding the following line in the <code>invenio_theme_tugraz/webpack.py</code> file, under the <code>semantic-ui</code> entries will do the trick. It will look something like this:</p> <pre><code>\"semantic-ui\": dict(\n            entry={\n                \"invenio-theme-tugraz-theme\": \"./less/invenio_theme_tugraz/theme.less\",\n                \"invenio-theme-tugraz-js\": \"./js/invenio_theme_tugraz/theme.js\",\n                # add search component\n                'invenio-theme-tugraz-rdm-search': './js/invenio_theme_tugraz/search/index.js',\n            }, ...\n</code></pre>"},{"location":"configs/override-pages/#adding-search-template","title":"Adding Search Template","text":"<p>To make use of the new search, a search template will be added. It will import our search app as previously defined in webpack. To achieve this, we will simply copy the current search page from invenio-rdm and replace the standard search app import with ours. Create the following file <code>invenio_theme_tugraz/templates/invenio_theme_tugraz/search.html</code> with the content of the base search template from invenio-app-rdm .</p> <p>In that file, all that has to be done is to replace the import:</p> <pre><code>{%- block javascript %}\n  {{ super() }}\n- {{ webpack['invenio-app-rdm-search.js'] }}\n+ {{ webpack['invenio-theme-tugraz-rdm-search.js'] }}\n{%- endblock %}\n</code></pre>"},{"location":"configs/override-pages/#override-config-variable","title":"Override Config Variable","text":"<p>Finally, invenio-rdm must know that it should use our new template for the search. This can be achieved by overriding the config variable <code>SEARCH_UI_SEARCH_TEMPLATE</code>. In <code>invenio_theme_tugraz/config.py</code> add or override the following line:</p> <pre><code>SEARCH_UI_SEARCH_TEMPLATE = \"invenio_theme_tugraz/search.html\"\n</code></pre> <p>Now invenio-rdm will use the new search template, which will use the new search app.</p>"},{"location":"configs/override-pages/#user-record-search","title":"User Record Search","text":"<p>The component to be overridden is <code>user_records_search</code> so the path for this looks like <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/user_records_search/</code>. Place the components in <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/user_records_search/components.js</code>.</p> <p>The original file can be found here: components.js</p>"},{"location":"configs/override-pages/#creating-search-app_1","title":"Creating Search App","text":"<p>Now that all components have been created or imported, create the following file <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/user_records_search/index.js</code>. In here, all the previously defined components will be imported and the search app will be defined.</p> <pre><code>import { createSearchAppInit } from \"@js/invenio_search_ui\";\nimport {\n  RDMRecordResultsListItem,\n  RDMRecordResultsGridItem,\n  RDMDepositResults,\n  RDMEmptyResults,\n  RDMUserRecordsSearchLayout,\n} from \"./components\";\nimport {\n  RDMBucketAggregationElement,\n  RDMCountComponent,\n  RDMRecordFacets,\n  RDMRecordFacetsValues,\n  RDMRecordSearchBarElement,\n  RDMToggleComponent,\n} from \"../search/components\";\n\nconst initSearchApp = createSearchAppInit({\n  \"BucketAggregation.element\": RDMBucketAggregationElement,\n  \"BucketAggregationValues.element\": RDMRecordFacetsValues,\n  \"Count.element\": RDMCountComponent,\n  \"EmptyResults.element\": RDMEmptyResults,\n  \"ResultsList.item\": RDMRecordResultsListItem,\n  \"ResultsGrid.item\": RDMRecordResultsGridItem,\n  \"SearchApp.facets\": RDMRecordFacets,\n  \"SearchApp.layout\": RDMUserRecordsSearchLayout,\n  \"SearchApp.results\": RDMDepositResults,\n  \"SearchBar.element\": RDMRecordSearchBarElement,\n  \"BucketAggregation.element\": RDMBucketAggregationElement,\n  \"BucketAggregationValues.element\": RDMRecordFacetsValues,\n  \"SearchFilters.ToggleComponent\": RDMToggleComponent,\n});\n</code></pre>"},{"location":"configs/override-pages/#update-webpack_1","title":"Update webpack","text":"<p>Now that the functionality is done, it is important to add it to webpack. This makes it accessible to templates. Adding the following line in the <code>invenio_theme_tugraz/webpack.py</code> file, under the <code>semantic-ui</code> entries will do the trick. It will look something like this:</p> <pre><code>\"semantic-ui\": dict(\n            entry={\n                \"invenio-theme-tugraz-theme\": \"./less/invenio_theme_tugraz/theme.less\",\n                \"invenio-theme-tugraz-js\": \"./js/invenio_theme_tugraz/theme.js\",\n                # add user record search component\n                'invenio-theme-tugraz-rdm-user-records-search': './js/invenio_theme_tugraz/user_records_search/index.js',\n            }, ...\n</code></pre>"},{"location":"configs/override-pages/#adding-search-template_1","title":"Adding Search Template","text":"<p>To make use of the new search, a search template will be added. It will import our search app as previously defined in webpack. To achieve this, we will simply copy the current search page from invenio-rdm and replace the standard search app import with ours. Create the following file <code>invenio_theme_tugraz/templates/invenio_theme_tugraz/records/search_deposit.html</code> with the content of the base user records search template from invenio-app-rdm .</p> <p>In that file, all that has to be done is to replace the import:</p> <pre><code>{%- block javascript %}\n  {{ super() }}\n- {{ webpack['invenio-app-rdm-user-records-search.js'] }}\n+ {{ webpack['invenio-theme-tugraz-rdm-user-records-search.js'] }}\n{%- endblock javascript %}\n</code></pre>"},{"location":"configs/override-pages/#adding-render-function","title":"Adding Render Function","text":"<p>Next, in <code>invenio_theme_tugraz/deposits.py</code> we define a function which will render the previously created template and pass the <code>searchbar_config</code> as argument.</p> <pre><code>from flask import render_template\nfrom flask_login import login_required\nfrom invenio_app_rdm.records_ui.views.deposits import get_search_url\n\n\n@login_required\ndef deposit_search():\n    \"\"\"List of user deposits page.\"\"\"\n    return render_template(\n        \"invenio_theme_tugraz/records/search_deposit.html\",\n        searchbar_config=dict(searchUrl=get_search_url()),\n    )\n</code></pre>"},{"location":"configs/override-pages/#adding-url-route","title":"Adding URL Route","text":"<p>All that is left is to add a URL rule, so that the new function is called instead of the one from the base implementation. In <code>invenio_theme_tugraz/ext.py</code> import the previously defined function</p> <pre><code>from invenio_theme_tugraz.deposits import deposit_search\n</code></pre> <p>and inside the <code>init_app</code> function add:</p> <pre><code>app.add_url_rule(\"/uploads\", \"deposit_search\", deposit_search)\n</code></pre> <p>Now invenio-rdm will use the new user record search template, which will use the new search app.</p>"},{"location":"configs/override-pages/#record-landing-page","title":"Record Landing Page","text":"<p>Since we do not need to add additional functionality to the record landing page, there is no need for new components or updating the webpack file. We will simply add and modify the html file and add the URL route. If there is need for additional functionality, follow the steps from the search page guide.</p>"},{"location":"configs/override-pages/#adding-detail-template","title":"Adding Detail Template","text":"<p>Create the following file <code>invenio_theme_tugraz/templates/invenio_theme_tugraz/records/detail.html</code> with the content of the base record detail template from invenio-app-rdm .</p> <p>Modify the template file as you see fit.</p>"},{"location":"configs/override-pages/#adding-render-function_1","title":"Adding Render Function","text":"<p>Next, in <code>invenio_theme_tugraz/deposits.py</code> we define a function which will render the previously created template and pass arguments needed by the template.</p> <pre><code>from flask import render_template\nfrom invenio_app_rdm.records_ui.views.decorators import (\n    pass_is_preview,\n    pass_record_files,\n    pass_record_or_draft,\n)\nfrom invenio_rdm_records.resources.serializers import UIJSONSerializer\n\n\n@pass_is_preview\n@pass_record_files\n@pass_record_or_draft\ndef record_detail(record=None, files=None, pid_value=None, is_preview=False):\n    \"\"\"Record detail page (aka landing page).\"\"\"\n    files_dict = None if files is None else files.to_dict()\n\n    return render_template(\n        \"invenio_theme_tugraz/records/detail.html\",\n        record=UIJSONSerializer().serialize_object_to_dict(record.to_dict()),\n        pid=pid_value,\n        files=files_dict,\n        permissions=record.has_permissions_to(['edit', 'new_version', 'manage',\n                                               'update_draft', 'read_files']),\n        is_preview=is_preview,\n    )\n</code></pre>"},{"location":"configs/override-pages/#adding-url-route_1","title":"Adding URL Route","text":"<p>All that is left is to add a URL rule, so that the new function is called instead of the one from the base implementation. In <code>invenio_theme_tugraz/ext.py</code> import the previously defined function</p> <pre><code>from invenio_theme_tugraz.deposits import record_detail\n</code></pre> <p>and inside the <code>init_app</code> function add:</p> <pre><code>app.add_url_rule(\"/records/&lt;pid_value&gt;\", \"record_detail\", record_detail)\n</code></pre> <p>Now invenio-rdm will use the new record detail template when displaying a record.</p>"},{"location":"configs/override-pages/#deposit-page","title":"Deposit Page","text":"<p>The component to be overridden is <code>deposit</code> so the path for this looks like <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/deposit/</code>. Place the components in <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/deposit/RDMDepositForm.js</code>.</p> <p>The original file can be found here: RDMDepositForm.js</p>"},{"location":"configs/override-pages/#rendering-deposit-form","title":"Rendering Deposit Form","text":"<p>Now that all components have been created or imported, create the following file <code>invenio_theme_tugraz/assets/semantic-ui/js/invenio_theme_tugraz/deposit/index.js</code>. In here, all the previously defined components will be imported and the deposit form will be rendered.</p> <pre><code>import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"semantic-ui-css/semantic.min.css\";\n\nimport { getInputFromDOM } from \"react-invenio-deposit\";\nimport { RDMDepositForm } from \"./RDMDepositForm\";\n\nReactDOM.render(\n  &lt;RDMDepositForm\n    record={getInputFromDOM(\"deposits-record\")}\n    files={getInputFromDOM(\"deposits-record-files\")}\n    config={getInputFromDOM(\"deposits-config\")}\n    permissions={getInputFromDOM(\"deposits-record-permissions\")}\n  /&gt;,\n  document.getElementById(\"deposit-form\")\n);\n</code></pre>"},{"location":"configs/override-pages/#update-webpack_2","title":"Update webpack","text":"<p>Now that the functionality is done, it is important to add it to webpack. This makes it accessible to templates. Adding the following line in the <code>invenio_theme_tugraz/webpack.py</code> file, under the <code>semantic-ui</code> entries will do the trick. It will look something like this:</p> <pre><code>\"semantic-ui\": dict(\n            entry={\n                \"invenio-theme-tugraz-theme\": \"./less/invenio_theme_tugraz/theme.less\",\n                \"invenio-theme-tugraz-js\": \"./js/invenio_theme_tugraz/theme.js\",\n                # add deposit component\n                'invenio-theme-tugraz-rdm-deposit': './js/invenio_theme_tugraz/deposit/index.js',\n            }, ...\n</code></pre>"},{"location":"configs/override-pages/#adding-deposit-template","title":"Adding Deposit Template","text":"<p>To make use of the new deposit form, a template will be added. It will import the deposit form as previously defined in webpack. To achieve this, we will simply copy the current deposit page from invenio-rdm and replace the standard deposit form import with ours. Create the following file <code>invenio_theme_tugraz/templates/invenio_theme_tugraz/records/deposit.html</code> with the content of the base deposit form template from invenio-app-rdm .</p> <p>In that file, all that has to be done is to replace the import:</p> <pre><code>{%- block javascript %}\n  {{ super() }}\n- {{ webpack['invenio-app-rdm-deposit.js'] }}\n+ {{ webpack['invenio-theme-tugraz-rdm-deposit.js'] }}\n{%- endblock %}\n</code></pre>"},{"location":"configs/override-pages/#adding-render-function_2","title":"Adding Render Function","text":"<p>Next, in <code>invenio_theme_tugraz/deposits.py</code> we define two functions which will render the previously created template and pass arguments needed by the template.</p> <p>First the create function, which is called when the user wants to create a new record:</p> <pre><code>from flask import render_template\nfrom flask_login import login_required\nfrom invenio_app_rdm.records_ui.views.decorators import (\n    pass_draft,\n    pass_draft_files,\n)\nfrom invenio_app_rdm.records_ui.views.deposits import (\n    get_form_config,\n    get_search_url,\n    new_record,\n)\nfrom invenio_rdm_records.resources.serializers import UIJSONSerializer\n\n\n@login_required\ndef deposit_create():\n    \"\"\"Create a new deposit.\"\"\"\n    return render_template(\n        \"invenio_theme_tugraz/records/deposit.html\",\n        forms_config=get_form_config(createUrl=(\"/api/records\")),\n        searchbar_config=dict(searchUrl=get_search_url()),\n        record=new_record(),\n        files=dict(\n            default_preview=None, entries=[], links={}\n        ),\n    )\n</code></pre> <p>Second the edit function, which is called when the user wants to edit an existing record:</p> <pre><code>@login_required\n@pass_draft\n@pass_draft_files\ndef deposit_edit(draft=None, draft_files=None, pid_value=None):\n    \"\"\"Edit an existing deposit.\"\"\"\n    record = UIJSONSerializer().serialize_object_to_dict(draft.to_dict())\n\n    return render_template(\n        \"invenio_theme_tugraz/records/deposit.html\",\n        forms_config=get_form_config(apiUrl=f\"/api/records/{pid_value}/draft\"),\n        record=record,\n        files=draft_files.to_dict(),\n        searchbar_config=dict(searchUrl=get_search_url()),\n        permissions=draft.has_permissions_to(['new_version'])\n    )\n</code></pre>"},{"location":"configs/override-pages/#adding-url-route_2","title":"Adding URL Route","text":"<p>All that is left is to add URL rules, so that the new functions are called instead of the ones from the base implementation. In <code>invenio_theme_tugraz/ext.py</code> import the previously defined functions</p> <pre><code>from invenio_theme_tugraz.deposits import deposit_create, deposit_edit\n</code></pre> <p>and inside the <code>init_app</code> function add:</p> <ul> <li>For new records: </li> </ul> <pre><code>app.add_url_rule(\"/uploads/new\", \"deposit_create\", deposit_create)\n</code></pre> <ul> <li>For editing existing records:</li> </ul> <pre><code>app.add_url_rule(\"/uploads/&lt;pid_value&gt;\", \"deposit_edit\", deposit_edit)`\n</code></pre> <p>Now invenio-rdm will use the new deposit form, when creating a new record or updating an existing record.</p>"},{"location":"configs/override-pages/#troubleshoot","title":"Troubleshoot","text":""},{"location":"configs/override-pages/#manifestkeynotfounderror","title":"ManifestKeyNotFoundError","text":"<ul> <li>check if the spelling of the webpack names matches with the import in the template.</li> <li>reinstall invenio-theme-tugraz<ul> <li>In order to pick up all the new files and to rebuild webpack, it is necessary to install <code>invenio-theme-tugraz</code> again. If no such changes happened, this step can be skipped.</li> <li><code>invenio-cli packages install /path/to/invenio-theme-tugraz</code></li> </ul> </li> </ul>"},{"location":"configs/postgresql/","title":"PostgreSQL","text":"<p>PostgreSQL also known as Postgres, is a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.</p> <p>In this guideline we will take a look on the Postgresql database setup and configurations for Repository Production instance. Using PostgreSQL Version <code>11</code>, and VM <code>invenio03-prod.tugraz.at</code></p>"},{"location":"configs/postgresql/#installation","title":"Installation","text":"<pre><code>$ apt-get update\n$ apt-get install postgresql postgresql-contrib\n</code></pre> <p>By default PostgreSQL has a default user <code>postgres</code>. We can access the database with this user <code>su postgres</code> and access the shell with  <code>psql</code>.</p> <p>To change the <code>postgres</code> user password:</p> <pre><code>$ su postgres\n(postgres) $ psql\n(postgres) ALTER USER postgres WITH PASSWORD '************';\n</code></pre>"},{"location":"configs/postgresql/#users-and-database","title":"Users and Database","text":"<p>Create a admin user:</p> <pre><code>CREATE USER &lt;USERNAME&gt; WITH PASSWORD '************';\n</code></pre> <p>Give the user permissions:</p> <pre><code>ALTER USER \"USERNAME\" WITH SUPERUSER;\n</code></pre> <p>Create Database:</p> <pre><code>CREATE database DATABASE_NAME;\n</code></pre> <p>Grant permissions of database for created user:</p> <pre><code>GRANT ALL PRIVILEGES ON DATABASE \"DATABASE_NAME\" to USER;\n</code></pre>"},{"location":"configs/postgresql/#configuration","title":"Configuration","text":""},{"location":"configs/postgresql/#allow-access","title":"Allow access","text":"<p>Allow remote connection to the webserver VMs.</p> <p>Open the <code>/etc/postgresql/11/main/pg_hba.conf</code> file and edit it as below:</p> <pre><code># TYPE  DATABASE        USER         ADDRESS              METHOD\nhost    all             &lt;user&gt;       ********/28          trust\nhost    all             &lt;user&gt;       ********/28          trust\nhost    all             &lt;user&gt;       repository.tugraz.at trust\n</code></pre>"},{"location":"configs/postgresql/#listen-address","title":"Listen address","text":"<p>Listen to other VMs.</p> <p>Open the <code>/etc/postgresql/11/main/postgresql.conf</code> file and edit it as below:</p> <pre><code>#------------------------------------------------------------------------------\n# CONNECTIONS AND AUTHENTICATION\n#------------------------------------------------------------------------------\n\n# - Connection Settings -\n\n- #listen_addresses = 'localhost'         # what IP address(es) to listen on;\n+ listen_addresses = '&lt;ip addresses&gt;'     # what IP address(es) to listen on;\n</code></pre>"},{"location":"configs/postgresql/#test-connection","title":"Test connection","text":"<p>Access the database from one of the configured machines.</p> <p>psql</p> <p>Make sure you have postgres client installed.</p> <pre><code>psql -U USERNAME -d DATABASE -h HOST_IP\n</code></pre>"},{"location":"configs/postgresql/#backup-restore","title":"Backup &amp; Restore","text":""},{"location":"configs/postgresql/#requirements","title":"Requirements","text":"<ul> <li>A server running Linux operating system with PostgreSQL installed.</li> <li>A root password is setup on your server.</li> </ul>"},{"location":"configs/postgresql/#backup-a-single-postgresql-database","title":"Backup a Single PostgreSQL Database","text":"<p>You will need to use pg_dump tool to backup a PostgreSQL database. This tool will dump all content of a database into a single file.</p> <p>The basic syntax to backup a PostgreSQL database is shown below:</p> <pre><code>pg_dump -U [option] [database_name] &gt; [backup_name]\n</code></pre> <p>A brief explanation of all available option is shown below:</p> <ul> <li>-U : Specify the PostgreSQL username.</li> <li>-W : Force pg_dump command to ask for a password.</li> <li>-F : Specify the format of the output file.</li> <li>-f : Specify the output file.</li> <li>p : Plain text SQL script.</li> <li>c : Specify the custom formate.</li> <li>d : Specify the directory format.</li> <li>t : Specify tar format archive file.</li> </ul> <p>For example, create a backup of the PostgreSQL database named db1 in the tar format, run the following command:</p> <pre><code>pg_dump -U postgres -F c db1 &gt; db1.tar\n</code></pre> <p>If you want to save the backup in a Plain-text (SQL), run the following command:</p> <pre><code>pg_dump db1 &gt; db1_backup.sql\n</code></pre> <p>If you want to save the backup in a directory format, run the following command:</p> <pre><code>pg_dump -U postgres -F d db1 &gt; db1_backup\n</code></pre> <p>If your database is very large and wants to generate a small backup file then you can use pg_dump with a compression tool such as gzip to compress the database backup.</p> <pre><code>pg_dump -U postgres db1 | gzip &gt; db1.gz\n</code></pre> <p>You can also reduce the database backup time by dumping number_of_jobs tables simultaneously using the -j flag.</p> <pre><code>pg_dump -U postgres -F d -j 5 db1 -f db1_backup\n</code></pre> <p>Note : Also keep in mind that the above command will reduce the time of the backup but it also increases the load on the server.</p>"},{"location":"configs/postgresql/#restore-a-single-postgresql-database","title":"Restore a Single PostgreSQL Database","text":"<p>If you choose custom, directory, or archive format when taking a database backup. Then, you will need to use pg_restore command to restore your database.</p> <p>The basic syntax to restore a database with pg_restore is shown below:</p> <pre><code>pg_restore -U [option] [db_name] [db_backup]\n</code></pre> <p>A brief explanation of each option is shown below:</p> <ul> <li>-c : Used to drop database objects before recreating them.</li> <li>-C : Used to create a database before restoring into it.</li> <li>-e : Exit if an error has been encountered.</li> <li>-F format : Used to specify the format of the archive.</li> </ul> <p>For example, restore a backup from the file db1.tar, you will need to consider two options:</p> <ol> <li>If the database already exists.</li> <li>The format of your backup.</li> </ol> <p>If your database already exists, you can restore it with the following command:</p> <pre><code>pg_restore -U postgres -Ft -d db1 &lt; db1.tar\n</code></pre> <p>If your database is not exists, you can restore it with the following command:</p> <pre><code>pg_restore -U postgres -Ft -C -d db1 &lt; db1.tar\n</code></pre>"},{"location":"configs/postgresql/#backup-a-remote-postgresql-database","title":"Backup a Remote PostgreSQL Database","text":"<p>In order to perform the database backup on the remote PostgreSQL server. You will need to configure your PostgreSQL server to allow remote connection.</p> <p>The basic syntax to backup a remote PostgreSQL database is shown below:</p> <pre><code>pg_dump -h [remote-postgres-server-ip] -U [option] [database_name] &gt; [backup_name]\n</code></pre> <p>For example, create a backup of the PostgreSQL database on the remote server ( 192.168.0.100 ) with name remote_db1 in the tar format, run the following command:</p> <pre><code>pg_dump -h 192.168.0.100 -U postgres -F c remote_db1 &gt; remote_db1.tar\n</code></pre>"},{"location":"configs/postgresql/#restore-a-remote-postgresql-database","title":"Restore a Remote PostgreSQL Database","text":"<p>The basic syntax to restore a remote PostgreSQL database is shown below:</p> <pre><code>pg_restore -h [remote-postgres-server-ip] -U [option] [database_name] &lt; [backup_name]\n</code></pre> <p>For example, restore a database from the file remote_db1.tar on the remote server ( 192.168.0.100 ), run the following command:</p> <pre><code>pg_restore -h 192.168.0.100 -U postgres -Ft -d remote_db1 &lt; remote_db1.tar\n</code></pre> <p>Note to restore from plain-text format you need to use <code>psql</code> command instead:</p> <pre><code>psql db1 &lt; db1_backup.sql\n</code></pre> <p>For more information, you can see the pg_dump and pg_restore reference pages.</p>"},{"location":"configs/sshkey/","title":"SSH-key","text":"<p>Services VM deployment is using direct <code>ssh</code> commands to reach the VM. In order to know the ssh keys configuration, please take a look into the steps below:</p>"},{"location":"configs/sshkey/#generate-ssh-key-in-vm","title":"Generate ssh-key in VM","text":"<p>This command will generate a new ssh-key.</p> <pre><code>$ ssh-keygen\n</code></pre> <pre><code>Your identification has been saved in /root/.ssh/id_rsa.\nYour public key has been saved in /root/.ssh/id_rsa.pub.\n</code></pre>"},{"location":"configs/sshkey/#add-private-key-to-cicd-variable","title":"Add private key to CI/CD variable","text":"<p>we have defined a variable <code>PROD_03_PRIVATE_KEY</code> in our Gitlab invenio group variable. And we are adding the generated private key <code>/root/.ssh/id_rsa</code> to <code>PROD_03_PRIVATE_KEY</code>.</p>"},{"location":"configs/sshkey/#authorized_keys","title":"authorized_keys","text":"<p>The authorized_keys file in SSH specifies the SSH keys that can be used for logging into the user account for which the file is configured.</p> <p>Add public key to authorized_keys:</p> <pre><code>$ cat  /root/.ssh/id_rsa.pub &gt;&gt; /.ssh/authorized_keys\n</code></pre>"},{"location":"configs/sshkey/#known_hosts","title":"known_hosts","text":"<p>group runner Gitlab-Runner-03-Produktion-Invenio-Shell has a <code>known_hosts</code> that contains a list of public keys for all the hosts which the user has connected to.</p> <p>These list of public keys are in CI/CD variable <code>SSH_SERVER_HOSTKEYS</code>.</p> <p>To add new host:</p> <pre><code>$ ssh-keyscan invenio03-prod.tugraz.at\n</code></pre> <p>And then update the variable <code>SSH_SERVER_HOSTKEYS</code>.</p>"},{"location":"deployment/","title":"Infrastructure","text":""},{"location":"deployment/#tu-graz-repository-has-3-instance-running-on-debian-vms","title":"Tu Graz Repository has 3 instance running on Debian (VMs).","text":"<p>&gt; Production Instance</p> <p>&gt; Test Instance</p> <p>&gt; Development Instance</p>"},{"location":"deployment/deploy/","title":"Deploy","text":"<p>Ready to deploy your changes in one of our instances:</p> <p>In this guideline, we will take a look at when the pipeline for different instances is executed.</p> <ol> <li>Deploy Dev (Development instance) </li> <li>Deploy Test (Test instance)</li> <li>Deploy Production (Production instance)</li> </ol>"},{"location":"deployment/deploy/#deploy-dev","title":"Deploy Dev","text":"<p>Every time there is a branch <code>dev</code> or <code>merge_request</code> to the branch master of Repository the pipeline stage for <code>dev</code> is executed.</p>"},{"location":"deployment/deploy/#pipeline","title":"Pipeline","text":""},{"location":"deployment/deploy/#deploy-test","title":"Deploy Test","text":"<p>Every commit or merge to the master branch of Repository will run Pipeline and deploy the changes to the Test instance.</p>"},{"location":"deployment/deploy/#pipeline_1","title":"Pipeline","text":""},{"location":"deployment/deploy/#deploy-production","title":"Deploy Production","text":"<p>Every new <code>Tag/release</code> of the Repository will run Pipeline and  deploy the changes to the Production instance.</p>"},{"location":"deployment/deploy/#steps","title":"Steps","text":"<p>Deployment to production requires a new <code>Tag/release</code> of the Repository. Meaning we should only deploy to production when we have a new <code>Tag/release</code>.</p> <p>1. Before creating a new <code>Tag/release</code> first we must change the value of <code>TAG_PROD</code> in GitLab CI/CD variables, to our expected new <code>Tag/release</code> version.</p> <p>For example the following change in <code>TAG_PROD</code> variable:</p> <pre><code>- v2.0.2\n+ v2.0.3\n</code></pre> <p>2. Create a new <code>Tag/release</code> for the Repository, using semantic-versioning.    for example <code>v2.0.3</code>, same value as in the <code>TAG_PROD</code> file.</p> <p>For Example using git:</p> <p><code>git tag -a v2.0.3 -m \"my version 0.1.2\"</code></p>"},{"location":"deployment/deploy/#pipeline_2","title":"Pipeline","text":""},{"location":"deployment/dev/","title":"Development instance","text":"<p>Coming soon</p>"},{"location":"deployment/production/","title":"Production Instance","text":"<p>repository.tugraz.at</p> <p>Production instance has 3 VMs:</p> <ol> <li>Web Server VM (invenio01-prod)</li> <li>Web Server VM (invenio02-prod)</li> <li>Services VM (invenio03-prod)</li> </ol> <p>These virtual machines are split into two categories, Web Servers and Services. In this guideline we will take a look on both:</p>"},{"location":"deployment/production/#web-server","title":"Web Server","text":"<p>Base image of the repository instance.</p> <ul> <li> <p>uWSGI is a software application that \"aims at developing a full stack for building hosting services\". uwsgi (all lowercase) is the native binary protocol that uWSGI uses to communicate with other servers.</p> </li> <li> <p>Celery is asynchronous task queue or job queue which is based on distributed message passing. While it supports scheduling, its focus is on operations in real time.</p> </li> </ul> <p>Alongside our base image, we are also pushing a NGINX container as a front-end proxy.</p> <ul> <li>Nginx is a web server that can also be used as a reverse proxy, load balancer, mail proxy and HTTP cache. </li> </ul> <p>The web server VMs are configured to the F5 load balancer that is provided by Tu Graz ZID.</p> <p>The F5 load balancer is forwarding the requests to one of the (Web Server VM), and then the requests are proxied by NGINX to UWSGI web applications. As shown below:</p> <p></p> <p>The gitlab repository Repository is the Web server, which holds all the files and data to build the application's base image and run the docker containers to our instances.</p> <p>The base image is a Docker image that will include all the dependencies required to run the application web-server, and its build with the help of Dockerfile and the commands define in it.</p> <p>From the base image then we are running three containers web-ui, web-api, and a worker with the help of the docker-compose file, as shown below.</p> <p></p> <p>Alongside these three containers from the base image, the docker-compose is also responsible to push a NGINX container to our servers. which then proxies the requests to the web-ui, and web-api, as shown below:</p> <p></p>"},{"location":"deployment/production/#docker-compose","title":"docker-compose","text":"<p>docker-compose is a tool for defining and running multi-container Docker applications.</p> <p>docker-compose-prod.yml</p> <pre><code># -*- coding: utf-8 -*-\n#\n# Copyright (C) 2021 Graz University of Technology\n#\n# Following services are included:\n# - Frontend server: Nginx (exposed port: 8080)\n# - UI application: UWSGI (not exposed)\n# - API application: UWSGI (not exposed)\n# - Worker: Celery (not exposed)\n\nversion: '2.2'\nservices:\n  # Frontend\n  frontend:\n    image: registry.gitlab.tugraz.at/invenio/nginx:prod\n    restart: \"always\"\n    volumes:\n      - static_data:/opt/invenio/var/instance/static\n    links:\n      - web-ui\n      - web-api\n    ports:\n      - \"8080:8080\"\n\n  # UI Application\n  web-ui:\n    command: [\"uwsgi /opt/invenio/var/instance/uwsgi_ui.ini\"]\n    image: registry.gitlab.tugraz.at/invenio/repository:${TAG_PROD}\n    env_file: ${ENV_FILE_PROD}\n    ports:\n      - \"5000\"\n    volumes:\n      - static_data:/opt/invenio/var/instance/static\n      - uploaded_data:/opt/invenio/var/instance/data\n      - archived_data:/opt/invenio/var/instance/archive\n\n  # API Rest Application\n  web-api:\n    command: [\"uwsgi /opt/invenio/var/instance/uwsgi_rest.ini\"]\n    image: registry.gitlab.tugraz.at/invenio/repository:${TAG_PROD}\n    env_file: ${ENV_FILE_PROD}\n    ports:\n      - \"5000\"\n    volumes:\n      - uploaded_data:/opt/invenio/var/instance/data\n      - archived_data:/opt/invenio/var/instance/archive\n\n  # Worker\n  worker:\n    restart: \"always\"\n    env_file: ${ENV_FILE_PROD}\n    command: [\"celery -A invenio_app.celery worker --loglevel=INFO\"]\n    image: registry.gitlab.tugraz.at/invenio/repository:${TAG_PROD}\n\nvolumes:\n  static_data:\n  uploaded_data:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /storage\n  archived_data:\n</code></pre>"},{"location":"deployment/production/#dockerfile","title":"Dockerfile","text":"<p>A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image.</p> <p>The Dockerfile for Repository, as below.</p> <pre><code># Dockerfile that builds a fully functional image of your app.\n#\n# This image installs all Python dependencies for your application. It's based\n# on CentOS 8 with Python 3.8 (https://github.com/inveniosoftware/docker-invenio)\n# and includes Pip, Pipenv, Node.js, NPM and some few standard libraries\n# Repository usually needs.\n\n# Pulling Centos8 with python3.8 image.\nFROM inveniosoftware/centos8-python:3.8\n\n# env arg\nARG ENVIRONMENT\n\n# These packages are required for shibboleth authentication.\n# Installing xmlsec packages\nRUN yum localinstall -y http://mirror.centos.org/centos/8/PowerTools/x86_64/os/Packages/xmlsec1-devel-1.2.25-4.el8.x86_64.rpm \\\n                        http://mirror.centos.org/centos/8/PowerTools/x86_64/os/Packages/xmlsec1-openssl-devel-1.2.25-4.el8.x86_64.rpm\n\n# Installing libtool package\nRUN yum localinstall -y http://mirror.centos.org/centos/8/AppStream/x86_64/os/Packages/libtool-ltdl-devel-2.4.6-25.el8.x86_64.rpm\n\n# Copy Pipfile and pipfile.lock to ./ directory\nCOPY Pipfile Pipfile.lock ./\n# Install all the dependecies defined in the Pipfile.\nRUN pipenv install --deploy --system --pre\n\n# Copy other necessary files\nCOPY ./docker/uwsgi/ ${INVENIO_INSTANCE_PATH}\nCOPY ./prod/invenio.cfg ${INVENIO_INSTANCE_PATH}\nCOPY ./templates/ ${INVENIO_INSTANCE_PATH}/templates/\nCOPY ./app_data/ ${INVENIO_INSTANCE_PATH}/app_data/\nCOPY ./ .\n\n# This will create, install and build all the statics &amp; assets. \nRUN cp -r ./static/. ${INVENIO_INSTANCE_PATH}/static/ &amp;&amp; \\\n    cp -r ./assets/. ${INVENIO_INSTANCE_PATH}/assets/ &amp;&amp; \\\n    invenio collect --verbose  &amp;&amp; \\\n    invenio webpack create &amp;&amp; \\\n    invenio webpack install --unsafe &amp;&amp; \\\n    invenio webpack build\n\n\n# Instruction used to configure how the container will run.\nENTRYPOINT [ \"bash\", \"-c\"]\n</code></pre>"},{"location":"deployment/production/#pipeline","title":"Pipeline","text":""},{"location":"deployment/production/#gitlab-ciyml","title":".gitlab-ci.yml","text":"<p>is a YAML file that you create on your project's root. This file automatically runs whenever you push code in the repository. Pipelines consist of one or more stages that run in order and can each contain one or more jobs that run in parallel. These jobs (or scripts) get executed by the GitLab Runner agent.</p> <p>Repository production pipeline consist of three stages:</p>"},{"location":"deployment/production/#build_prod","title":"build_prod","text":"<p>In this stage the pipeline is building base image for Production instance.</p> <p>Login to docker, clean docker cache, for containers, volumes and images.</p> <pre><code>  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n</code></pre> <p>Build and push base image to gitlab Container Registry. Using Tag name <code>CI_COMMIT_TAG</code>, which is a reference to the latest repository tag/release.</p> <pre><code>  script:\n    - echo \"Build base image...\" \n    - docker build --no-cache -t \"$CI_REGISTRY_IMAGE\":$CI_COMMIT_TAG --build-arg ENVIRONMENT=PROD . \n    - echo \"Push image to the gitlab registry...\" \n    - docker push \"$CI_REGISTRY_IMAGE\":$CI_COMMIT_TAG\n</code></pre> <p>Logout from docker</p> <pre><code>  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n</code></pre> <p>Only run for <code>tags</code>.</p> <pre><code>  only:\n    - tags\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>shell</code>:</p> <pre><code>  tags:\n   - shell\n</code></pre> <p>Full build_prod stage:</p> <pre><code>build_prod:\n  stage: build_prod\n  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n  script:\n    - echo \"Build base image...\" \n    - docker build --no-cache -t \"$CI_REGISTRY_IMAGE\":$CI_COMMIT_TAG --build-arg ENVIRONMENT=PROD . \n    - echo \"Push image to the gitlab registry...\" \n    - docker push \"$CI_REGISTRY_IMAGE\":$CI_COMMIT_TAG\n  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n  only:\n    - tags\n  tags:\n   - shell\n</code></pre>"},{"location":"deployment/production/#prod_one-deploy","title":"prod_one-deploy","text":"<p>In this stage pipeline is deploying the base image to the Web Server(invenio01-prod).</p> <p>Login to docker, clean docker cache, containers, volumes &amp; images.</p> <pre><code>  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker-compose -f docker-compose.prod.yml down\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n</code></pre> <p>Run docker-compose, pull images and run containers defined in <code>docker-compose.prod.yml</code> file.</p> <pre><code>  script:\n    - echo \"run docker-compose...\"\n    - docker-compose -f docker-compose.prod.yml up -d\n</code></pre> <p>Logout from docker</p> <pre><code>  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n</code></pre> <p>Only run for <code>tags</code>.</p> <pre><code>  only:\n    - tags\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>prod01</code>:</p> <pre><code>  tags:\n   - prod01\n</code></pre> <p>Full prod_one-deploy stage:</p> <pre><code>prod_one-deploy:\n  stage: prod_one\n  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker-compose -f docker-compose.prod.yml down\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n\n  script:\n    - echo \"run docker-compose...\"\n    - docker-compose -f docker-compose.prod.yml up -d\n  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n  only:\n    - tags\n  tags:\n   - prod01\n</code></pre>"},{"location":"deployment/production/#prod_two-deploy","title":"prod_two-deploy","text":"<p>In this stage pipeline is deploying the base image to the Web Server(invenio02-prod).</p> <p>Login to docker, clean docker cache, containers, volumes &amp; images.</p> <pre><code>  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker-compose -f docker-compose.prod.yml down\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n</code></pre> <p>Run docker-compose, pull images and run containers defined in <code>docker-compose.prod.yml</code> file.</p> <pre><code>  script:\n    - echo \"run docker-compose...\"\n    - docker-compose -f docker-compose.prod.yml up -d\n</code></pre> <p>Logout from docker</p> <pre><code>  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n</code></pre> <p>Only run for <code>tags</code>.</p> <pre><code>  only:\n    - tags\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>prod02</code>:</p> <pre><code>  tags:\n   - prod02\n</code></pre> <p>Full test_two stage:</p> <pre><code>prod_two-deploy:\n  stage: prod_two\n  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker-compose -f docker-compose.prod.yml down\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n\n  script:\n    - echo \"run docker-compose...\"\n    - docker-compose -f docker-compose.prod.yml up -d\n  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n  only:\n    - tags\n  tags:\n   - prod02\n</code></pre>"},{"location":"deployment/production/#full-gitlab-ciyml","title":"Full .gitlab-ci.yml","text":"<pre><code># Pipline stages\nstages:\n  - build_prod\n  - prod_one\n  - prod_two\n\nbuild_prod:\n  stage: build_prod\n  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n  script:\n    - echo \"Build base image...\" \n    - docker build --no-cache -t \"$CI_REGISTRY_IMAGE\":$CI_COMMIT_TAG --build-arg ENVIRONMENT=PROD . \n    - echo \"Push image to the gitlab registry...\" \n    - docker push \"$CI_REGISTRY_IMAGE\":$CI_COMMIT_TAG\n  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n  only:\n    - tags\n  tags:\n   - shell\n\n# Deploy stage for web server 01\nprod_one-deploy:\n  stage: prod_one\n  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker-compose -f docker-compose.prod.yml down\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n\n  script:\n    - echo \"run docker-compose...\"\n    - docker-compose -f docker-compose.prod.yml up -d\n  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n  only:\n    - tags\n  tags:\n   - prod01\n\n# Deploy stage for web server 02\nprod_two-deploy:\n  stage: prod_two\n  before_script:\n    - echo \"login to docker...\"\n    - echo \"$CI_REGISTRY_PASSWORD\" | docker login -u \"$CI_REGISTRY_USER\" --password-stdin \"$CI_REGISTRY\"\n    - echo \"Clean docker cache, for containers, volumes and images...\"\n    - docker-compose -f docker-compose.prod.yml down\n    - docker system prune -f --volumes\n    - docker system prune -a -f\n    - docker image prune -f\n\n  script:\n    - echo \"run docker-compose...\"\n    - docker-compose -f docker-compose.prod.yml up -d\n  after_script:\n    - echo \"Logout from docker...\" \n    - \"docker logout ${CI_REGISTRY}\"\n  only:\n    - tags\n  tags:\n   - prod02\n</code></pre>"},{"location":"deployment/production/#services","title":"Services","text":"<p>TU Graz Repository consist of these services:</p> <ul> <li> <p>Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents. Elasticsearch is developed in Java.</p> </li> <li> <p>PostgreSQL is a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance.</p> </li> <li> <p>Redis Remote Dictionary Server is an in-memory data structure project implementing a distributed, in-memory key\u2013value database with optional durability. Redis supports different kinds of abstract data structures, such as strings, lists, maps, sets, sorted sets, HyperLogLogs, bitmaps, streams, and spatial indexes.</p> </li> <li> <p>EXIM4 Exim4 is a Message Transfer Agent (MTA) developed at the University of Cambridge for use on Unix systems connected to the Internet. Exim can be installed in place of sendmail, although its configuration is quite different.</p> </li> <li> <p>RabbitMQ RabbitMQ is an open-source message-broker software that originally implemented the Advanced Message Queuing Protocol and has since been extended with a plug-in architecture to support Streaming Text Oriented Messaging Protocol, MQ Telemetry Transport.</p> </li> </ul> <p>These services have a seperate repository in the Gitlab Group invenio.</p> <p>Except PostgreSQL other Services deployment are the same.</p> <p>As an Example we will have a look into our Elasticsearch deployment.</p>"},{"location":"deployment/production/#elasticsearch","title":"Elasticsearch","text":""},{"location":"deployment/production/#dockerfile_1","title":"Dockerfile","text":"<p>A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image.</p> <p>The Dockerfile for Elasticsearch, as below.</p> <pre><code># Pull elasticsearch version 7\nFrom docker.elastic.co/elasticsearch/elasticsearch-oss:7.9.3\n\n# add single-node config\nRUN echo \"discovery.type: single-node\" &gt;&gt; /usr/share/elasticsearch/config/elasticsearch.yml\n\n# define docker User\nUSER elasticsearch\n</code></pre>"},{"location":"deployment/production/#deploy-prodsh","title":"deploy-prod.sh","text":"<p>Is a helper file for deployment, and used by .gitlab-ci.yml. It contains instruction for docker commands.</p> <pre><code>CONTAINER_NAME=elasticsearch\nIMAGE_NAME=registry.gitlab.tugraz.at/invenio/elasticsearch:latest\n\necho \"################################################\"\necho \"Stopping and removing container with given name......$CONTAINER_NAME\"\ndocker stop $CONTAINER_NAME || true &amp;&amp; docker rm $CONTAINER_NAME || true\n\necho \"################################################\"\necho \"Removing image if given name exists...$IMAGE_NAME\"\nif test ! -z \"$(docker images -q $IMAGE_NAME)\"; then\n  echo \"Image exist...\"\n  docker rmi -f $IMAGE_NAME\nfi\n\necho \"################################################\"\necho \"Running new container..............\"\ndocker run --name=\"$CONTAINER_NAME\" \\\n--mount type=bind,source=/storage,target=/usr/share/elasticsearch/data \\\n--memory 1g -p 9200:9200 -p 9300:9300 -d \\\n-e bootstrap.memory_lock=true \\\n-e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n-e discovery.type=single-node \\\n--health-cmd=\"curl --fail localhost:9200/_cluster/health?wait_for_status=green || exit 1\" \\\n--health-interval=30s \\\n--health-retries=5 \\\n--health-timeout=30s \\\n--restart=always \\\n$IMAGE_NAME\n\necho \"################################################\"\necho \"job ended...\"\n</code></pre>"},{"location":"deployment/production/#gitlab-ciyml_1","title":".gitlab-ci.yml","text":"<p>Elasticsearch pipeline consist of two stages</p>"},{"location":"deployment/production/#build","title":"build","text":"<p>Pipeline builds the docker image and pushes it to the Registry.</p> <p>Login to docker:</p> <pre><code>  before_script:\n    - echo \"################################\"\n    - echo \"login to docker...\"\n    - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY\n</code></pre> <p>Build and push docker image:</p> <pre><code>  script:\n    - echo \"################################\"\n    - echo \"Building the image...\"\n    - docker build -t \"$CI_REGISTRY_IMAGE\" .\n    - echo \"push image to registry...\"\n    - docker push \"$CI_REGISTRY_IMAGE\"\n</code></pre> <p>Only run for branch <code>master</code>:</p> <pre><code>  only:\n    - master\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>shell</code>:</p> <pre><code>  tags:\n   - shell\n</code></pre>"},{"location":"deployment/production/#test","title":"test","text":"<p>In this stage the pipeline pulls the newly created image and creates a container to the VM.</p> <p><code>before_script</code> run followings:</p> <ul> <li>Install ssh-agent if not already installed, it is required by Docker.</li> <li>Run ssh-agent (inside the build environment)</li> <li>Add the SSH key stored in PROD_03_PRIVATE_KEY variable to the agent store</li> <li>Create the SSH directory and give it the right permissions</li> <li>scan the keys of your private server from variable <code>SSH_SERVER_HOSTKEYS</code></li> </ul> <pre><code>  before_script:\n    - echo \"SSH-USER\"\n    - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client git -y )'\n    - eval $(ssh-agent -s)\n    - echo \"$PROD_03_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - echo \"$SSH_SERVER_HOSTKEYS\" &gt; ~/.ssh/known_hosts\n    - chmod 644 ~/.ssh/known_hosts\n</code></pre> <p><code>script</code>:  using <code>ssh</code> commands logs in to docker, and runs scripts in <code>deploy-prod.sh</code> to our server.</p> <pre><code>  script:\n    - ssh $PROD_03_DOMAIN \"echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin\"\n    - ssh $PROD_03_DOMAIN \"eval '$(cat ./deploy-test.sh)'\"\n</code></pre> <p>Only run for branch <code>master</code>:</p> <pre><code>  only:\n    - master\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>shell</code>:</p> <pre><code>  tags:\n   - shell\n</code></pre>"},{"location":"deployment/production/#prod","title":"prod","text":"<p>In this stage the pipeline pulls the newly created image and creates a container to the Production instance.</p> <p><code>before_script</code> run followings:</p> <ul> <li>Install ssh-agent if not already installed, it is required by Docker.</li> <li>Run ssh-agent (inside the build environment)</li> <li>Add the SSH key stored in PROD_03_PRIVATE_KEY variable to the agent store</li> <li>Create the SSH directory and give it the right permissions</li> <li>scan the keys of your private server from variable <code>SSH_SERVER_HOSTKEYS</code></li> </ul> <pre><code>  before_script:\n    - echo \"SSH-USER\"\n    - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client git -y )'\n    - eval $(ssh-agent -s)\n    - echo \"$PROD_03_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - echo \"$SSH_SERVER_HOSTKEYS\" &gt; ~/.ssh/known_hosts\n    - chmod 644 ~/.ssh/known_hosts\n</code></pre> <p><code>script</code>:  using <code>ssh</code> commands logs in to docker, and runs scripts in <code>deploy-prod.sh</code> to our server.</p> <pre><code>  script:\n    - ssh $PROD_03_DOMAIN  \"echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin\"\n    - ssh $PROD_03_DOMAIN  \"eval '$(cat ./deploy-prod.sh)'\"\n</code></pre> <p>Only run for branch <code>master</code>:</p> <pre><code>  only:\n    - master\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>shell</code>:</p> <pre><code>  tags:\n   - shell\n</code></pre>"},{"location":"deployment/production/#full-gitlab-ciyml_1","title":"Full .gitlab-ci.yml","text":"<pre><code>stages:\n  - build\n  - prod\n\nbuild:\n  stage: build\n  before_script:\n    - echo \"################################\"\n    - echo \"login to docker...\"\n    - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY\n  script:\n    - echo \"################################\"\n    - echo \"Building the image...\"\n    - docker build -t \"$CI_REGISTRY_IMAGE\" .\n    - echo \"push image to registry...\"\n    - docker push \"$CI_REGISTRY_IMAGE\"\n  only:\n    - master\n  tags:\n   - shell\n\nprod:\n  stage: prod\n  before_script:\n    - echo \"################################\"\n    - echo \"SSH-USER\"\n  ##\n  ## Install ssh-agent if not already installed, it is required by Docker.\n  ## (change apt-get to yum if you use an RPM-based image)\n  ##\n    - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client git -y )'\n  ##\n  ## Run ssh-agent (inside the build environment)\n  ##\n    - eval $(ssh-agent -s)\n  ##\n  ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store\n  ## We're using tr to fix line endings which makes ed25519 keys work\n  ## without extra base64 encoding.\n  ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556\n  ##\n    - echo \"$PROD_03_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n  ##\n  ## Create the SSH directory and give it the right permissions\n  ##\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n  ##\n  ## Use ssh-keyscan to scan the keys of your private server. Replace gitlab.com\n  ## with your own domain name. You can copy and repeat that command if you have\n  ## more than one server to connect to.\n  ##\n    #- ssh-keyscan invenio03-test.tugraz.at &gt;&gt; ~/.ssh/known_hosts\n    #- chmod 644 ~/.ssh/known_hosts\n  ##\n  ## Alternatively, assuming you created the SSH_SERVER_HOSTKEYS variable\n  ## previously, uncomment the following two lines instead.\n  ##\n    - echo \"$SSH_SERVER_HOSTKEYS\" &gt; ~/.ssh/known_hosts\n    - chmod 644 ~/.ssh/known_hosts\n\n  script:\n    - echo \"################################\"\n    - ssh $PROD_03_DOMAIN \"echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin\"\n    - ssh $PROD_03_DOMAIN \"eval '$(cat ./deploy-prod.sh)'\"\n  only:\n    - master\n  tags:\n   - shell\n</code></pre>"},{"location":"deployment/test/","title":"Test Instance","text":"<p>invenio-test.tugraz.at</p> <p>Test instance has 3 VMs:</p> <ol> <li>Web Server VM (invenio01-test)</li> <li>Web Server VM (invenio02-test)</li> <li>Services VM (invenio03-test)</li> </ol> <p>Test instance configuration is same as &gt; Production Instance.</p>"},{"location":"deployment/vms/","title":"VMs update &amp; upgrade","text":"<p>Backup</p> <p>Make sure you have a regular backup of VMs set up! </p> <p>In total the repository uses 7 virtual machines, in order to keep the packages up to date, we need to run the <code>update</code> &amp; <code>upgrade</code> commands in regular bases.</p> <p>For this we have created a new repository upgrade-vms, this repository consist of all the scripts and pipeline configuration to run our <code>update</code> &amp; <code>upgrade</code> scripts in specified time and date, for all the VMs.</p>"},{"location":"deployment/vms/#gitlab-ciyml","title":".gitlab-ci.yml","text":"<p>is a YAML file that you create on your project's root. This file automatically runs whenever specific intervals are met.</p> <p>This file consits of 7 stage, one stage for each virtual machines:</p> <pre><code>  - invenio-dev01\n  - invenio01-test\n  - invenio02-test\n  - invenio03-test\n  - invenio01-prod\n  - invenio02-prod\n  - invenio03-prod\n</code></pre> <p>All these above stages have the same identical steps, only the environment variables are different, we will cover one of these stage.</p> <p><code>before_script</code> run followings:</p> <ul> <li>Install ssh-agent if not already installed, it is required by Docker.</li> <li>Run ssh-agent (inside the build environment)</li> <li>Add the SSH key stored in TEST_01_PRIVATE_KEY variable to the agent store</li> <li>Create the SSH directory and give it the right permissions</li> <li>scan the keys of your private server from variable <code>SSH_SERVER_HOSTKEYS</code></li> </ul> <pre><code>  before_script:\n    - echo \"################################\"\n    - echo \"SSH-USER\"\n    - eval $(ssh-agent -s)\n    - echo \"$TEST_01_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - echo \"$SSH_SERVER_HOSTKEYS\" &gt; ~/.ssh/known_hosts\n    - chmod 644 ~/.ssh/known_hosts\n</code></pre> <p><code>script</code>:  using <code>ssh</code> runs scripts in <code>scripts.sh</code> to our server.</p> <pre><code>  script:\n    - echo \"################################\"\n    - ssh $TEST_01_DOMAIN \"eval '$(cat ./scripts-test.sh)'\"\n</code></pre> <p>Only run for branch <code>schedules</code>:</p> <pre><code>  only:\n    - schedules\n</code></pre> <p>Execute jobs with Gitlab-runner tag name <code>shell</code>:</p> <pre><code>  tags:\n   - shell\n</code></pre> <p>Full .gitlab-ci.yml:</p> <pre><code>invenio01-test:\n  stage: invenio01-test\n  before_script:\n    - echo \"################################\"\n    - echo \"SSH-USER\"\n    - eval $(ssh-agent -s)\n    - echo \"$TEST_01_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - echo \"$SSH_SERVER_HOSTKEYS\" &gt; ~/.ssh/known_hosts\n    - chmod 644 ~/.ssh/known_hosts\n  script:\n    - echo \"################################\"\n    - ssh $TEST_01_DOMAIN \"eval '$(cat ./scripts-test.sh)'\"\n  only:\n    - schedules\n  tags:\n   - shell\n</code></pre>"},{"location":"deployment/vms/#scripts-sh-file","title":"scripts-().sh file","text":"<p>scripts-test.sh &amp; scripts-prod.sh is a helper files for deployment, and used by <code>.gitlab-ci.yml</code>. It contains instruction for update/upgrade commands. And a <code>curl</code> check if nginx server is responding.</p> <pre><code>echo \"################################################\"\necho \"Run update &amp; upgrade scripts.\"\n\nexport DEBIAN_FRONTEND=noninteractive\napt-get update &amp;&amp; apt-get -q -y upgrade\n\n\necho \"################################################\"\necho \"Check if nginx server is running.\"\n\nnginxserver=********:8080\n\ncheck=$(curl -s -w \"%{http_code}\\n\" -L \"$nginxserver\" -o /dev/null)\nif [[ $check == 200 || $check == 403 ]]\nthen\n    # Server is online\n    echo \"Server is online\"\n    exit 0\nelse\n    # Server is offline or not working correctly\n    echo \"Server is offline or not working correctly\"\n    exit 1\nfi\n</code></pre>"},{"location":"deployment/vms/#configure-root-access-to-vms","title":"Configure root access to VMS.","text":"<p>The <code>update</code> &amp; <code>upgrade</code> shell commands require root access to the virtual machines. We are using ssh-keys to access the virtual machines with root permission.</p> <p>Please see the SSH-key configuration for further details.</p>"},{"location":"deployment/vms/#pipeline-schedules","title":"Pipeline schedules","text":"<p>Now that we have our <code>scripts</code> and <code>pipeline configuration</code> ready, lets configure Gitlab pipeline schedules.</p> <p>Gitlab pipelines are normally run based on certain conditions being met. For example, when a branch is pushed to repository.</p> <p>Pipeline schedules can be used to also run pipelines at specific intervals. For example:</p> <ul> <li>Every month on the 22nd for a certain branch.</li> <li>Once every day.</li> </ul>"},{"location":"deployment/vms/#configuring-pipeline-schedules","title":"Configuring pipeline schedules","text":"<p>To schedule a pipeline for project:</p> <ol> <li>Navigate to the project\u2019s CI/CD &gt; Schedules page.</li> <li>Click the New schedule button.</li> <li>Fill in the Schedule a new pipeline form.</li> <li>Click the Save pipeline schedule button.</li> </ol> <p></p> <p>In the Schedules index page you can see a list of the pipelines that are scheduled to run. The next run is automatically calculated by the server GitLab is installed on. </p>"},{"location":"features/","title":"Details about features specific to TU Graz repository.","text":""},{"location":"features/#global-search","title":"Global search","text":"<p>How to integrate <code>Invenio-Records-Global-Search</code> and <code>Invenio-Global-Search</code> packages into TU Graz repository.</p> <p>&gt; Global search</p>"},{"location":"features/#publications","title":"Publications","text":"<p>How to integrate <code>Invenio-Records-Marc21</code> package into TU Graz repository.</p> <p>&gt; Publications</p>"},{"location":"features/#oer","title":"OER","text":"<p>How to integrate <code>Invenio-Records-Lom</code> package into TU Graz repository.</p> <p>&gt; OER</p>"},{"location":"features/#curations","title":"Curations","text":"<p>How to integrate <code>Invenio-Curations</code> package into TU Graz repository.</p> <p>&gt; Curations</p>"},{"location":"features/curations/","title":"Curations feature","text":"<p>invenio-curations is an Invenio package that adds curation reviews to TU Graz Repository.</p> <p>Out of the box, the Repository already provides reviews for records as part of the submission or inclusion into communities. However, there is no requirement per default for records to be part of any community at all. Thus, it is generally easy for users to self-publish records in the Repository without any further review.</p>"},{"location":"features/curations/#setup","title":"Setup","text":"<p>After the successful installation of <code>Invenio-Curations</code>, it still needs to be configured properly to work. The following sections should guide you through the required adaptations.</p>"},{"location":"features/curations/#inveniocfg","title":"invenio.cfg","text":"<p>Because this package is now part of the Repository, we included its overriden configurations in invenio-config-tugraz. But, even so, we still need to update some core InvenioRDM configs in order to get it working. For default configurations please refer to the curations package.</p> <ul> <li>Include the curation component in the RDM components list</li> </ul> <pre><code>from invenio_config_tugraz.components import TUGRAZ_RDM_RECORDS_SERVICE_COMPONENTS\n\nRDM_RECORDS_SERVICE_COMPONENTS = TUGRAZ_RDM_RECORDS_SERVICE_COMPONENTS + [RDMToGlobalSearchComponent]\n</code></pre> <ul> <li>Update Requests permission policy</li> <li>Update Notification Builders</li> <li>Update Requests Facets</li> <li>Update Registered Event types</li> </ul> <pre><code>from invenio_config_tugraz.permissions import TUGrazRDMRequestsPermissionPolicy\nfrom invenio_config_tugraz.facets import TUGRAZ_REQUESTS_FACETS\nfrom invenio_config_tugraz.notifications import TUGRAZ_NOTIFICATIONS_BUILDERS\nfrom invenio_config_tugraz.requests import TUGRAZ_REQUESTS_REGISTERED_EVENT_TYPES\n\nREQUESTS_PERMISSION_POLICY = TUGrazRDMRequestsPermissionPolicy\nREQUESTS_FACETS = TUGRAZ_REQUESTS_FACETS\nNOTIFICATIONS_BUILDERS = TUGRAZ_NOTIFICATIONS_BUILDERS\nREQUESTS_REGISTERED_EVENT_TYPES = TUGRAZ_REQUESTS_REGISTERED_EVENT_TYPES\n</code></pre>"},{"location":"features/curations/#curations-ui","title":"Curations UI","text":"<p>The changes so far have dealt with setting up the mechanism for the curation workflow in the backend. To also make the workflow accessible for users through the UI, some frontend components have to be updated as well.</p> <p>Invenio-Curations provides a few component overrides. These overrides need to be registered in the overridable registry (i.e. in the repository's assets/js/invenio_app_rdm/overridableRegistry/mapping.js):</p> <pre><code>import { curationComponentOverrides } from \"@js/invenio_curations/requests\";\nimport { DepositBox } from \"@js/invenio_curations/deposit/DepositBox\";\n\nexport const overriddenComponents = {\n    // ... after your other overrides ...\n    ...curationComponentOverrides,\n    \"InvenioAppRdm.Deposit.CardDepositStatusBox.container\": DepositBox,\n};\n</code></pre>"},{"location":"features/curations/#curator-role","title":"Curator role","text":"<p>The permission to manage curation requests is controlled by a specific role in the system. The default configured role is administration-rdm-records-curation. Add this role to the curators for TU Graz repository in order for them to have access to the flow.</p> <p>Commands to achieve this:</p> <pre><code>invenio roles create administration-rdm-records-curation\ninvenio roles add &lt;curator_mail&gt; administration-rdm-records-curation\n</code></pre>"},{"location":"features/curations/#bypass-curation","title":"Bypass curation","text":"<p>Add the following configuration variable to the <code>invenio.cfg</code> file to enable bypassing the curation workflow. The list contains roles that can be assigned to users.</p> <p>Ensure that the role exists and assign it to the user who should be allowed to bypass the curation workflow.</p> <p>cli</p> <pre><code>invenio roles create bypass-curation\ninvenio roles add &lt;email&gt; bypass-curation\n</code></pre> <p>invenio.cfg</p> <pre><code>CURATIONS_PRIVILEGED_ROLES: list[str] = [\"bypass-curation\"]\n</code></pre>"},{"location":"features/gs/","title":"Global Search feature","text":"<p>invenio-global-search is an Invenio package that provides a unified search interface across different record types (RDM records, MARC21 publications, LOM educational resources) in the Repository.</p> <p>Note: Global search is most useful when you have multiple data models (e.g., RDM + MARC21, or RDM + LOM). If you only have RDM records, the built-in RDM search is sufficient and global search may not be necessary.</p> <p>This guide explains how to set up global search for research results, with examples for adding additional record types.</p>"},{"location":"features/gs/#setup","title":"Setup","text":"<p>After the successful installation of <code>invenio-global-search</code>, it needs to be configured properly to work. The following sections should guide you through the required adaptations.</p>"},{"location":"features/gs/#installation","title":"Installation","text":"<p>Add <code>invenio-global-search</code> to your <code>pyproject.toml</code>:</p> <pre><code>[project]\ndependencies = [\n    \"invenio-global-search&gt;=0.3.0\",\n    # ... other dependencies\n]\n</code></pre> <p>Then update your lock file:</p> <pre><code>uv sync\n</code></pre>"},{"location":"features/gs/#inveniocfg","title":"invenio.cfg","text":"<p>The global search component needs to be added to the RDM records service components, and you need to configure the global search interface to show research results.</p> <p>Add the following configuration to your theme's <code>invenio.cfg</code> (e.g., <code>themes/YOUR_THEME/invenio.cfg</code>):</p> <pre><code>GLOBAL_SEARCH_SCHEMAS = {\n    \"rdm\": {\n        \"schema\": \"rdm\",\n        \"name_l10n\": \"Research Result\",\n    },\n}\n\"\"\"Mapping of schemas for global search - only RDM (Research Results) are shown.\"\"\"\n</code></pre> <p>Note: If you want to add additional record types (e.g., MARC21 publications or LOM educational resources), you must have the corresponding packages installed (<code>invenio-records-marc21</code> for publications, <code>invenio-records-lom</code> for educational resources). See the Adding Additional Record Types section below.</p>"},{"location":"features/gs/#component-configuration","title":"Component Configuration","text":"<p>For each record type you want to include in global search, you need to add the corresponding component to the service components. This ensures that records are automatically indexed in the global search database when they are created or updated.</p> <p>For RDM records:</p> <pre><code>from invenio_global_search.components import RDMToGlobalSearchComponent\nfrom invenio_rdm_records.services.components import (\n    DefaultRecordsComponents as RDMDefaultRecordsComponents,\n)\n\nRDM_RECORDS_SERVICE_COMPONENTS = RDMDefaultRecordsComponents + [\n    RDMToGlobalSearchComponent\n]\n</code></pre> <p>For MARC21 publications (if installed):</p> <pre><code>from invenio_global_search.components import Marc21ToGlobalSearchComponent\nfrom invenio_records_marc21.services.components import (\n    DefaultRecordsComponents as Marc21DefaultRecordsComponents,\n)\n\nMARC21_RECORDS_SERVICE_COMPONENTS = Marc21DefaultRecordsComponents + [\n    Marc21ToGlobalSearchComponent\n]\n</code></pre> <p>For LOM educational resources (if installed):</p> <pre><code>from invenio_global_search.components import LOMToGlobalSearchComponent\nfrom invenio_records_lom.services.components import (\n    DefaultRecordsComponents as LOMDefaultRecordsComponents,\n)\n\nLOM_RECORDS_SERVICE_COMPONENTS = LOMDefaultRecordsComponents + [\n    LOMToGlobalSearchComponent\n]\n</code></pre>"},{"location":"features/gs/#initialize-global-search-database","title":"Initialize Global Search Database","text":"<p>After configuring global search, you need to initialize the global search database:</p> <pre><code>invenio global-search rebuild-database\n</code></pre> <p>This command creates the necessary database tables for storing global search records.</p>"},{"location":"features/gs/#ui-customization","title":"UI Customization","text":"<p>The global search feature uses the global search template for the main search page. Configure this in your <code>invenio.cfg</code>:</p> <pre><code>SEARCH_UI_SEARCH_TEMPLATE = \"invenio_records_global_search/search/search.html\"\n</code></pre> <p>This ensures that users hitting \"Enter\" in the search bar are directed to the global search interface, which shows research results.</p> <p>Important: After setting <code>SEARCH_UI_SEARCH_TEMPLATE</code> to use the global search template, the default RDM records search route will no longer be accessible. You need to create a new route for RDM records search if you want to provide direct access to RDM-only search. This is typically done by adding a custom view/route in your theme package.</p>"},{"location":"features/gs/#adding-additional-record-types","title":"Adding Additional Record Types","text":"<p>To make global search more useful, you can add additional record types such as MARC21 publications or LOM educational resources.</p> <p>Prerequisites: You must have the corresponding packages installed: - For MARC21 publications: <code>invenio-records-marc21</code> - For LOM educational resources: <code>invenio-records-lom</code></p> <p>After installing the respective packages, you need to: 1. Add the component to the service components (see Component Configuration above) 2. Update your <code>GLOBAL_SEARCH_SCHEMAS</code> configuration</p> <p>Example: Adding MARC21 Publications</p> <pre><code>GLOBAL_SEARCH_SCHEMAS = {\n    \"rdm\": {\n        \"schema\": \"rdm\",\n        \"name_l10n\": \"Research Result\",\n    },\n    \"marc21\": {\n        \"schema\": \"marc21\",\n        \"name_l10n\": \"Publication\",\n    },\n}\n</code></pre> <p>Example: Adding LOM Educational Resources</p> <pre><code>GLOBAL_SEARCH_SCHEMAS = {\n    \"rdm\": {\n        \"schema\": \"rdm\",\n        \"name_l10n\": \"Research Result\",\n    },\n    \"lom\": {\n        \"schema\": \"lom\",\n        \"name_l10n\": \"OER\",\n    },\n}\n</code></pre>"},{"location":"features/oer/","title":"todo","text":""},{"location":"features/publications/","title":"todo","text":""},{"location":"services/","title":"Services","text":"<p>&gt; pgAdmin</p>"},{"location":"services/pgadmin/","title":"pgAdmin","text":"<p>The pgAdmin package is a free and open-source graphical user interface (GUI) administration tool for PostgreSQL, which is configured as a service for your development.</p> <p>docker-services.yml</p> <pre><code>  pgadmin:\n    image: dpage/pgadmin4\n    ports:\n      - \"5050:5050\"\n    environment:\n      - PGADMIN_DEFAULT_EMAIL=&lt;your_email_address&gt;\n      - PGADMIN_DEFAULT_PASSWORD=&lt;your_password&gt;\n      - PGADMIN_LISTEN_PORT=5050\n</code></pre> <p>docker-compose.yml</p> <pre><code>  pgadmin:\n    extends:\n      file: docker-services.yml\n      service: pgadmin\n</code></pre> <p>You can easily access pgAdmin 4 from your web browser.</p> <p>visit http://localhost:5050. You should see the pgAdmin login page. Login with your email and password.</p> <p></p> <p>Once you login, you should see the pgAdmin dashboard.</p> <p></p> <p>Now, to add the PostgreSQL server running as a Docker container, right click on Servers, and then go to Create &gt; Server\u2026</p> <p></p> <p>In the General tab, type in your server Name.</p> <p></p> <p>Now, go to the Connection tab and type in <code>db</code> as Host name/address, (db is the container name for PostgreSQL) 5432 as Port, postgres as Maintenance database, admin as Username, secret as Password and check Save password? checkbox. Then, click on Save.</p> <p>NOTE: Ad <code>Host name/address</code> add docker container name or service name of your database. in real production it can be the IP of address of Database.</p> <p></p> <p>pgAdmin 4 should be connected to your PostgreSQL database. Now, you can work with your PostgreSQL database as much as you want.</p> <p></p>"}]}